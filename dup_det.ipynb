{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ca64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8327241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_page_img(file):\n",
    "    \n",
    "def extract_text(img):\n",
    "    \n",
    "def similarity_cal(text1,text2):\n",
    "    \n",
    "def find_duplicate_images(folder_path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a217bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz # PyMuPDF library\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def extract_first_page_img(file):\n",
    "\n",
    "    # Open PDF file\n",
    "    with fitz.open(file) as pdf:\n",
    "        # Load the first page\n",
    "        page = pdf.load_page(0)\n",
    "\n",
    "        # Convert the page to a pixmap object\n",
    "        pix = page.get_pixmap()\n",
    "\n",
    "        # Convert the pixmap object to a PIL Image object\n",
    "        pil_img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "        # Save the image to file (optional)\n",
    "        #pil_img.save('imagescs.png')\n",
    "        return pil_img\n",
    "def extract_text(img):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0baa46e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-Levenshtein==0.12.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b24bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def check_similarity(text1, text2):\n",
    "    distance = Levenshtein.distance(text1, text2)\n",
    "    similarity = 1 - (distance / max(len(text1), len(text2)))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a71642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define the function to find duplicate images in a folder\n",
    "threshold=0.9\n",
    "\n",
    "def find_duplicate_images(folder_path):\n",
    "    # Create a set to store the paths of duplicate images\n",
    "    set_of_paths = set()\n",
    "    # Traverse the folder and check for duplicate images\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for i in range(len(filenames)):\n",
    "           # 0 10\n",
    "            filename1 = filenames[i]\n",
    "            filepath1 = os.path.join(dirpath, filename1)\n",
    "            img1= extract_first_page_img(filepath1)\n",
    "            text1= extract_text(img1)\n",
    "            \n",
    "\n",
    "            for j in range(i+1, len(filenames)):\n",
    "            #  0  1 10\n",
    "                filename2 = filenames[j]\n",
    "                filepath2 = os.path.join(dirpath, filename2)\n",
    "                img2= extract_first_page_img(filepath2)\n",
    "                text2= extract_text(img2)\n",
    "                \n",
    "\n",
    "                # Predict the similarity of the two texts\n",
    "                similarity =check_similarity(text1, text2)\n",
    "\n",
    "                if similarity > threshold:\n",
    "                    # Duplicate image found\n",
    "                    print(f'Duplicate image found: {filename1} and {filename2} with similarity score {similarity}')\n",
    "                    set_of_paths.add(filepath2)\n",
    "                    \n",
    "                    \n",
    "    return list(set_of_paths)\n",
    "\n",
    "# Call the function to find duplicate images in a folder\n",
    "find_duplicate_images('path/to/folder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272d1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c84356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fa37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5bc9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557f254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d747439f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ad3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e2936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453cfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fed256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9cb428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76392363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfcbddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481cfbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Define the function to load and preprocess an image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "# Define the function to create a Siamese network\n",
    "def create_siamese_network(input_shape):\n",
    "    # Define the two input images\n",
    "    input_1 = Input(input_shape)\n",
    "    input_2 = Input(input_shape)\n",
    "\n",
    "    # Use the VGG16 model as the base model\n",
    "    base_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "    # Define the two branches of the Siamese network\n",
    "    branch_1 = base_model(input_1)\n",
    "    branch_2 = base_model(input_2)\n",
    "\n",
    "    # Define the similarity function\n",
    "    def euclidean_distance(vectors):\n",
    "        vector1, vector2 = vectors\n",
    "        sum_squared = K.sum(K.square(vector1 - vector2), axis=1, keepdims=True)\n",
    "        return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
    "\n",
    "    # Add a lambda layer to compute the similarity\n",
    "    similarity_layer = Lambda(euclidean_distance)([branch_1, branch_2])\n",
    "\n",
    "    # Define the output of the model\n",
    "    model = Model(inputs=[input_1, input_2], outputs=similarity_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the function to check for duplicate images in a folder\n",
    "def check_duplicate_images(folder_path):\n",
    "    # Load the trained Siamese network\n",
    "    siamese_model = create_siamese_network((224, 224, 3))\n",
    "    siamese_model.load_weights('path/to/siamese_network_weights.h5')\n",
    "\n",
    "    # Create an image data generator\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    # Traverse the folder and check for duplicate images\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for i in range(len(filenames)):\n",
    "           # 0 10\n",
    "            filename1 = filenames[i]\n",
    "            filepath1 = os.path.join(dirpath, filename1)\n",
    "            img1 = preprocess_image(filepath1)\n",
    "\n",
    "            for j in range(i+1, len(filenames)):\n",
    "            #  0  1 10\n",
    "                filename2 = filenames[j]\n",
    "                filepath2 = os.path.join(dirpath, filename2)\n",
    "                img2 = preprocess_image(filepath2)\n",
    "\n",
    "                # Predict the similarity of the two images\n",
    "                similarity = siamese_model.predict([img1, img2])[0][0]\n",
    "\n",
    "                if similarity < 0.1:\n",
    "                    # Duplicate image found\n",
    "                    print(f'Duplicate image found: {filename1} and {filename2} with similarity score {similarity}')\n",
    "\n",
    "# Call the function to check for duplicate images in a folder\n",
    "check_duplicate_images('path/to/folder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 2 5 4 5 2 7 2 7\n",
    "a b c d e f g h i\n",
    "\n",
    "f h e f h i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fa677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "# Define the function to compute the hash of an image file\n",
    "def hash_file(filename):\n",
    "    # Open the file in binary mode\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read the file contents in chunks\n",
    "        chunk = f.read(4096)\n",
    "        # Compute the hash of the file contents\n",
    "        md5_hash = hashlib.md5()\n",
    "        while chunk:\n",
    "            md5_hash.update(chunk)\n",
    "            chunk = f.read(4096)\n",
    "        return md5_hash.hexdigest()\n",
    "\n",
    "# Define the function to find duplicate images in a folder\n",
    "def find_duplicate_images(folder_path):\n",
    "    # Create a dictionary to store the hash values and filenames\n",
    "    hash_dict = {}\n",
    "    \n",
    "    # Traverse the folder and compute the hash of each image file\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                filehash = hash_file(filepath)\n",
    "                if filehash in hash_dict:\n",
    "                    \n",
    "                    ##if text match >95%\n",
    "                    # Duplicate image found\n",
    "                    print(f'Duplicate image found: {filepath} and {hash_dict[filehash]}')\n",
    "                    \n",
    "                    \n",
    "                    #also delete this file\n",
    "                else:\n",
    "                    # Add the hash value and filename to the dictionary\n",
    "                    hash_dict[filehash] = filepath\n",
    "\n",
    "# Call the function to find duplicate images in a folder\n",
    "find_duplicate_images('path/to/folder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6282e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def check_similarity(text1, text2, threshold):\n",
    "    distance = Levenshtein.distance(text1, text2)\n",
    "    similarity = 1 - (distance / max(len(text1), len(text2)))\n",
    "    return similarity >= threshold\n",
    "\n",
    "# Example usage\n",
    "text1 = \"Hello, world!\"\n",
    "text2 = \"Hello, world\"\n",
    "threshold = 0.9\n",
    "\n",
    "if check_similarity(text1, text2, threshold):\n",
    "    print(\"The texts are similar.\")\n",
    "else:\n",
    "    print(\"The texts are not similar.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
